# Агент для прогнозирования временных рядов (LangChain + Prophet)

## Описание проекта

Интеллектуальный ассистент на базе LangChain и Claude Haiku, который отвечает на вопросы о прогнозах и исторических данных по трем показателям: продажи (sales), цена (price) и поездки (trips). Агент использует Prophet для прогнозирования, поддерживает диалог с памятью и умеет отличать запросы о прошлом от запросов о будущем.

## Структура проекта
.
├── data/
│   ├── sales.csv                  # Исторические данные по продажам
│   ├── price.csv                  # Исторические данные по цене
│   ├── trips.csv                  # Исторические данные по поездкам
│   └── forecasts/                 # Сохраненные прогнозы Prophet
│       ├── prophet_forecast_sales.csv
│       ├── prophet_forecast_price.csv
│       └── prophet_forecast_trips.csv
├── prompts/
│   ├── classifier.txt             # Промпт для классификации запросов
│   ├── chat.txt                   # Промпт для светской беседы
│   └── forecast_response.txt      # Промпт для формирования ответа
├── key.txt                        # Ключ API
├── requirements.txt               # Зависимости проекта
├── agent.py                       # Основной код агента (LangChain)
└── forecast.py                    # Модель Prophet для прогнозирования


## Содержимое и функционал

### `forecast.py` — Модель Prophet
- **train(df)**: обучение модели на исторических данных с оптимальными параметрами
- **ensure_forecast_until(target_date)**: проверка и продление прогноза до указанной даты
- **get_forecast_for_date(target_date)**: получение данных (история или прогноз) на конкретную дату
- **get_forecast_for_period(start_date, end_date)**: получение данных за период (с авт. объединением истории и прогноза)
- Автоматическое разграничение: даты до 31.01.2026 берутся из истории, после — из прогноза

### `agent.py` — LangChain агент
- **Классификация запросов**: определяет тип запроса (forecast/history/greeting/small_talk)
- **Маршрутизация**: RunnableBranch направляет запросы к соответствующим обработчикам
- **Память диалога**: ConversationBufferMemory хранит историю общения
- **Обработка данных**: получение исторических данных или прогнозов через ProphetForecaster
- **Формирование ответа**: LLM генерирует человекопонятные ответы на основе данных


## Описание промптов

### `prompts/classifier.txt`
Промпт для классификации запросов пользователя. Определяет тип запроса (forecast/history/greeting/small_talk), показатель (sales/price/trips), дату или период. Содержит инструкцию возвращать строгий JSON и примеры для всех случаев.

### `prompts/chat.txt`
Промпт для светской беседы. Инструктирует модель быть дружелюбным ассистентом, поддерживать диалог и отвечать на общие вопросы, не связанные с прогнозированием.

### `prompts/forecast_response.txt`
Промпт для формирования человекопонятного ответа на основе данных прогноза или истории. Получает структурированные данные (JSON) и преобразует их в естественный язык с указанием единиц измерения и доверительных интервалов.


## Архитектура агента
Запрос пользователя
       ↓
[classifier_step] — определяет intent и извлекает дату/период
       ↓
[RunnableBranch] — маршрутизация
    ├── forecast/history → [handle_forecast] → получение данных → [format_forecast_response]
    ├── greeting/small_talk → [handle_conversation] → прямой ответ
    └── fallback → сообщение об ошибке
       ↓
Ответ пользователю + сохранение в память

## Метрики качества Prophet
После тюнинга гиперпараметров модель Prophet достигла следующих результатов:

- MAE: 7.77 на тестовом периоде (2025 год)
- Оптимальные параметры сохранены в forecast.py


## Использование

### 1. Установка зависимостей
```bash
pip install -r requirements.txt
```

### 2. Настройка API ключа:
Создайте файл key.txt в корне проекта и добавьте ваш ключ Anthropic API.

### 3. Запустите скрипт:
```bash
python agent.py
```

### 4. Общение:
Агент запускается в терминале и общается с пользователем через консольный ввод-вывод.
